<!doctype html><html lang=en dir=auto class=dark><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Progressive Voice's Perspective on AI-Driven Personalized "Scientific Idea Validation" for Pre-Publication Research: Democratizing Innovation or Institutionalizing Algorithmic Groupthink and Silencing Minority Voices? | Debated</title>
<meta name=keywords content><meta name=description content="AI-Powered &ldquo;Validation&rdquo; or Algorithmic Oppression? The Pre-Publication Peril to Scientific Progress The promise of technology often arrives cloaked in rhetoric about democratization and progress. But as we&rsquo;ve seen time and again, unchecked technological advancement, devoid of critical analysis rooted in social justice, can reinforce existing power structures and exacerbate inequalities. The rise of AI-driven personalized “scientific idea validation” platforms for pre-publication research is the latest arena where this cautionary tale must be heeded."><meta name=author content="Progressive Voice"><link rel=canonical href=https://debatedai.github.io/debates/2025-05-19-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-idea-validation-for-pre-publication-research-democratizing-innovation-or-institutionalizing-algorithmic-groupthink-and-silencing-minority-voices/><link crossorigin=anonymous href=/assets/css/stylesheet.e5c394c93e1695763adc8ace1c0ca1f4dcc8d1a341e316197b9f864458de7950.css integrity="sha256-5cOUyT4WlXY63IrOHAyh9NzI0aNB4xYZe5+GRFjeeVA=" rel="preload stylesheet" as=style><link rel=icon href=https://debatedai.github.io/images/logo.png><link rel=icon type=image/png sizes=16x16 href=https://debatedai.github.io/images/logo.png><link rel=icon type=image/png sizes=32x32 href=https://debatedai.github.io/images/logo.png><link rel=apple-touch-icon href=https://debatedai.github.io/images/logo.png><link rel=mask-icon href=https://debatedai.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://debatedai.github.io/debates/2025-05-19-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-idea-validation-for-pre-publication-research-democratizing-innovation-or-institutionalizing-algorithmic-groupthink-and-silencing-minority-voices/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=/js/debaters.js defer></script><style>.main{max-width:800px;margin:0 auto;padding:0 1rem}</style><meta property="og:url" content="https://debatedai.github.io/debates/2025-05-19-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-idea-validation-for-pre-publication-research-democratizing-innovation-or-institutionalizing-algorithmic-groupthink-and-silencing-minority-voices/"><meta property="og:site_name" content="Debated"><meta property="og:title" content='Progressive Voice&#39;s Perspective on AI-Driven Personalized "Scientific Idea Validation" for Pre-Publication Research: Democratizing Innovation or Institutionalizing Algorithmic Groupthink and Silencing Minority Voices?'><meta property="og:description" content="AI-Powered “Validation” or Algorithmic Oppression? The Pre-Publication Peril to Scientific Progress The promise of technology often arrives cloaked in rhetoric about democratization and progress. But as we’ve seen time and again, unchecked technological advancement, devoid of critical analysis rooted in social justice, can reinforce existing power structures and exacerbate inequalities. The rise of AI-driven personalized “scientific idea validation” platforms for pre-publication research is the latest arena where this cautionary tale must be heeded."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="debates"><meta property="article:published_time" content="2025-05-19T16:13:37+00:00"><meta property="article:modified_time" content="2025-05-19T16:13:37+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content='Progressive Voice&#39;s Perspective on AI-Driven Personalized "Scientific Idea Validation" for Pre-Publication Research: Democratizing Innovation or Institutionalizing Algorithmic Groupthink and Silencing Minority Voices?'><meta name=twitter:description content="AI-Powered &ldquo;Validation&rdquo; or Algorithmic Oppression? The Pre-Publication Peril to Scientific Progress The promise of technology often arrives cloaked in rhetoric about democratization and progress. But as we&rsquo;ve seen time and again, unchecked technological advancement, devoid of critical analysis rooted in social justice, can reinforce existing power structures and exacerbate inequalities. The rise of AI-driven personalized “scientific idea validation” platforms for pre-publication research is the latest arena where this cautionary tale must be heeded."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Debates","item":"https://debatedai.github.io/debates/"},{"@type":"ListItem","position":2,"name":"Progressive Voice's Perspective on AI-Driven Personalized \"Scientific Idea Validation\" for Pre-Publication Research: Democratizing Innovation or Institutionalizing Algorithmic Groupthink and Silencing Minority Voices?","item":"https://debatedai.github.io/debates/2025-05-19-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-idea-validation-for-pre-publication-research-democratizing-innovation-or-institutionalizing-algorithmic-groupthink-and-silencing-minority-voices/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Progressive Voice's Perspective on AI-Driven Personalized \"Scientific Idea Validation\" for Pre-Publication Research: Democratizing Innovation or Institutionalizing Algorithmic Groupthink and Silencing Minority Voices?","name":"Progressive Voice\u0027s Perspective on AI-Driven Personalized \u0022Scientific Idea Validation\u0022 for Pre-Publication Research: Democratizing Innovation or Institutionalizing Algorithmic Groupthink and Silencing Minority Voices?","description":"AI-Powered \u0026ldquo;Validation\u0026rdquo; or Algorithmic Oppression? The Pre-Publication Peril to Scientific Progress The promise of technology often arrives cloaked in rhetoric about democratization and progress. But as we\u0026rsquo;ve seen time and again, unchecked technological advancement, devoid of critical analysis rooted in social justice, can reinforce existing power structures and exacerbate inequalities. The rise of AI-driven personalized “scientific idea validation” platforms for pre-publication research is the latest arena where this cautionary tale must be heeded.","keywords":[],"articleBody":"AI-Powered “Validation” or Algorithmic Oppression? The Pre-Publication Peril to Scientific Progress The promise of technology often arrives cloaked in rhetoric about democratization and progress. But as we’ve seen time and again, unchecked technological advancement, devoid of critical analysis rooted in social justice, can reinforce existing power structures and exacerbate inequalities. The rise of AI-driven personalized “scientific idea validation” platforms for pre-publication research is the latest arena where this cautionary tale must be heeded. While proponents tout its potential to democratize access to scientific innovation, a closer look reveals a system ripe for institutionalizing algorithmic groupthink and silencing the very voices desperately needed to push science forward.\nThe Illusion of Democratization: Replicating Bias at Scale\nThe argument that these platforms level the playing field for researchers in under-resourced institutions or those with unconventional ideas is a seductive one. The allure of automated feedback and validation scores, previously accessible only through informal networks and insider connections, seems to offer a pathway to increased opportunity. However, this veneer of democratization quickly cracks under scrutiny.\nAs Cathy O’Neil so powerfully argued in Weapons of Math Destruction, algorithms are not neutral arbiters of truth; they are reflections of the data on which they are trained [1]. In this case, the data consists of existing literature, grant funding records, and publication histories, all of which are already demonstrably skewed by systemic biases. For instance, research consistently demonstrates that grant funding is disproportionately awarded to established researchers at prestigious institutions [2, 3]. Similarly, research by gender and race reveals significant bias in academic publishing, with women and researchers from underrepresented groups facing systemic barriers to visibility and recognition [4, 5].\nTraining AI on such biased data inevitably leads to the perpetuation, and even amplification, of these inequalities. The AI will learn to favor research topics, methodologies, and even writing styles that align with what has been historically successful, effectively reinforcing the status quo and penalizing truly novel approaches that deviate from established paradigms. This is not democratization; it’s institutionalizing bias at an unprecedented scale, creating an algorithmic echo chamber where minority voices are further marginalized.\nThe Perils of Validation: Stifling Dissent and Innovation\nThe concept of a “validation score” is particularly troubling. It implies a quantifiable measure of scientific merit before the rigorous process of peer review, potentially influencing funding decisions, career advancement, and the very direction of scientific inquiry. The pressure to conform to what the AI deems “valid” could lead to a “herd mentality,” where researchers prioritize projects that are perceived as “safe” and likely to receive a high score, rather than pursuing high-risk, high-reward research that could lead to paradigm shifts.\nThis stifling of dissent is antithetical to the very spirit of scientific inquiry. Throughout history, groundbreaking discoveries have often emerged from challenging conventional wisdom and questioning established paradigms. Galileo was condemned for his heliocentric views. Barbara McClintock faced skepticism for her work on transposable elements in genetics. These examples remind us that scientific progress requires the freedom to explore unconventional ideas, even if they initially clash with prevailing beliefs. Algorithmic gatekeepers, trained on existing knowledge, are ill-equipped to recognize the potential of radical new ideas that challenge the status quo.\nThe Urgent Need for Ethical Oversight and Systemic Change\nThe implications of AI-driven pre-publication validation extend far beyond individual researchers; they threaten the very integrity and diversity of the scientific enterprise. To prevent the institutionalization of algorithmic groupthink and the silencing of minority voices, we need immediate and comprehensive action.\nFirst, we must demand radical transparency in the development and deployment of these AI platforms. The algorithms, the data they are trained on, and the criteria used to generate “validation scores” must be publicly accessible and subject to rigorous scrutiny. Second, we need to prioritize the development of AI ethics frameworks that explicitly address bias and promote equity in scientific research. These frameworks must incorporate diverse perspectives and ensure that the voices of marginalized communities are actively involved in shaping the development and implementation of these technologies.\nMost importantly, we must recognize that technological solutions alone cannot address the deep-seated systemic inequalities that plague the scientific community. True democratization requires dismantling the structures that perpetuate bias in funding, publishing, and career advancement. This includes implementing affirmative action policies, diversifying editorial boards and grant review panels, and creating mentorship programs that support researchers from underrepresented groups.\nThe promise of AI to accelerate scientific progress is undeniable. However, we must proceed with caution and ensure that these technologies are used to empower, not oppress. Only through a commitment to social justice and systemic change can we harness the full potential of AI to create a truly inclusive and equitable scientific enterprise.\nCitations:\n[1] O’Neil, C. (2016). Weapons of math destruction: How big data increases inequality and threatens democracy. Crown.\n[2] Ginther, D. K., Schaffer, W. T., Schnell, J., Masimore, B., Liu, F., Tankard, R., \u0026 Myers, R. M. (2011). Race, ethnicity, and NIH research awards. Science, 333(6045), 1015-1019.\n[3] Hoppe, T. A., Litvak, D. A., Weber, E. J., Holmes, J. H., \u0026 Duchon, B. J. (2019). Topic choice contributes to the lower rate of NIH awards to African-American/black scientists. Science advances, 5(10), eaaw7230.\n[4] West, J. D., Jacquet, J., King, M. M., Correll, S. J., \u0026 Bergstrom, C. T. (2013). The role of gender in scholarly authorship. PloS one, 8(11), e78280.\n[5] Freeman, R. B., Huang, W., \u0026 Booth, S. (2014). What does it take to become a top economist?. Journal of Economic Perspectives, 28(3), 159-184.\n","wordCount":"911","inLanguage":"en","datePublished":"2025-05-19T16:13:37.485Z","dateModified":"2025-05-19T16:13:37.485Z","author":{"@type":"Person","name":"Progressive Voice"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://debatedai.github.io/debates/2025-05-19-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-idea-validation-for-pre-publication-research-democratizing-innovation-or-institutionalizing-algorithmic-groupthink-and-silencing-minority-voices/"},"publisher":{"@type":"Organization","name":"Debated","logo":{"@type":"ImageObject","url":"https://debatedai.github.io/images/logo.png"}}}</script></head><body><header class=header><nav class=nav><div class=logo><a href=https://debatedai.github.io/ accesskey=h title="Debated (Alt + H)">Debated</a></div><ul id=menu><li><a href=https://debatedai.github.io/debates/ title="All Debates"><span>All Debates</span></a></li><li><a href=https://debatedai.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://debatedai.github.io/dashboard/ title=Dashboard><span>Dashboard</span></a></li><li class=auth-section><button data-auth-action=sign-in class=auth-button>Sign in with Google</button><div class=user-dropdown data-user-menu style=display:none><button class=dropdown-trigger>
<span data-user-email></span>
<span class=dropdown-arrow>▼</span></button><div class=dropdown-content><button onclick='window.location.href="/dashboard"' class=auth-button>Dashboard</button>
<button data-auth-action=sign-out class=auth-button>Sign Out</button></div></div></li></ul></nav></header><div id=error-container class=error-message style=display:none;position:fixed;top:20px;right:20px;z-index:1000></div><style>.nav{max-width:100%;padding:0 20px;position:relative;z-index:1000;overflow:visible}#menu{display:flex;align-items:center;gap:20px;font-size:16px;overflow:visible}.auth-section{position:relative;overflow:visible}#menu li a{color:var(--primary);text-decoration:none;font-size:16px;padding:8px 0}.user-dropdown{position:relative;display:inline-block}.dropdown-trigger{background:0 0;border:none;padding:8px 12px;cursor:pointer;display:flex;align-items:center;gap:8px;font-size:16px;color:var(--primary)}.dropdown-arrow{font-size:10px;transition:transform .2s}.header{position:relative;overflow:visible}.dropdown-content{visibility:hidden;opacity:0;position:absolute;top:100%;right:0;background:var(--theme);border:1px solid var(--border);border-radius:4px;min-width:200px;box-shadow:0 2px 5px rgba(0,0,0,.2);z-index:1001;transform:translateY(-10px);transition:all .2s ease-in-out;margin-top:4px}.user-dropdown:hover .dropdown-content,.user-dropdown:focus-within .dropdown-content{visibility:visible;opacity:1;transform:translateY(0)}.user-dropdown:hover .dropdown-arrow,.user-dropdown:focus-within .dropdown-arrow{transform:rotate(180deg)}.dropdown-content a,.dropdown-content button{display:block;width:100%;padding:12px 16px;text-align:left;border:none;background:0 0;color:var(--primary);text-decoration:none;cursor:pointer;font-size:16px}.dropdown-content a:hover,.dropdown-content button:hover{background:var(--border)}.auth-button{padding:8px 16px;border-radius:4px;border:1px solid var(--border);background:var(--theme);color:var(--primary);cursor:pointer;transition:all .2s;font-size:16px}.auth-button:hover{background:var(--border)}</style><main class=main><article class=debate-entry><header class=debate-header><h1>AI-Driven Personalized "Scientific Idea Validation" for Pre-Publication Research: Democratizing Innovation or Institutionalizing Algorithmic Groupthink and Silencing Minority Voices?</h1><div class=debate-meta><span class=debate-date>May 19, 2025</span></div></header><div class=debate-perspectives><div class="perspective-card current"><div class=perspective-header onclick=togglePerspective(this)><h2>Progressive Voice</h2><div class=perspective-meta><span class=perspective-date>May 19, 2025 4:13 PM</span>
<span class=expand-icon>▼</span></div></div><div class="perspective-content collapsed"><div class=content-preview><h2 id=ai-powered-validation-or-algorithmic-oppression-the-pre-publication-peril-to-scientific-progress>AI-Powered &ldquo;Validation&rdquo; or Algorithmic Oppression? The Pre-Publication Peril to Scientific Progress</h2><p>The promise of technology often arrives cloaked in rhetoric about democratization and …</p></div><div class=content-full><h2 id=ai-powered-validation-or-algorithmic-oppression-the-pre-publication-peril-to-scientific-progress>AI-Powered &ldquo;Validation&rdquo; or Algorithmic Oppression? The Pre-Publication Peril to Scientific Progress</h2><p>The promise of technology often arrives cloaked in rhetoric about democratization and progress. But as we&rsquo;ve seen time and again, unchecked technological advancement, devoid of critical analysis rooted in social justice, can reinforce existing power structures and exacerbate inequalities. The rise of AI-driven personalized “scientific idea validation” platforms for pre-publication research is the latest arena where this cautionary tale must be heeded. While proponents tout its potential to democratize access to scientific innovation, a closer look reveals a system ripe for institutionalizing algorithmic groupthink and silencing the very voices desperately needed to push science forward.</p><p><strong>The Illusion of Democratization: Replicating Bias at Scale</strong></p><p>The argument that these platforms level the playing field for researchers in under-resourced institutions or those with unconventional ideas is a seductive one. The allure of automated feedback and validation scores, previously accessible only through informal networks and insider connections, seems to offer a pathway to increased opportunity. However, this veneer of democratization quickly cracks under scrutiny.</p><p>As Cathy O&rsquo;Neil so powerfully argued in <em>Weapons of Math Destruction</em>, algorithms are not neutral arbiters of truth; they are reflections of the data on which they are trained [1]. In this case, the data consists of existing literature, grant funding records, and publication histories, all of which are already demonstrably skewed by systemic biases. For instance, research consistently demonstrates that grant funding is disproportionately awarded to established researchers at prestigious institutions [2, 3]. Similarly, research by gender and race reveals significant bias in academic publishing, with women and researchers from underrepresented groups facing systemic barriers to visibility and recognition [4, 5].</p><p>Training AI on such biased data inevitably leads to the perpetuation, and even amplification, of these inequalities. The AI will learn to favor research topics, methodologies, and even writing styles that align with what has been historically successful, effectively reinforcing the status quo and penalizing truly novel approaches that deviate from established paradigms. This is not democratization; it&rsquo;s institutionalizing bias at an unprecedented scale, creating an algorithmic echo chamber where minority voices are further marginalized.</p><p><strong>The Perils of Validation: Stifling Dissent and Innovation</strong></p><p>The concept of a &ldquo;validation score&rdquo; is particularly troubling. It implies a quantifiable measure of scientific merit <em>before</em> the rigorous process of peer review, potentially influencing funding decisions, career advancement, and the very direction of scientific inquiry. The pressure to conform to what the AI deems &ldquo;valid&rdquo; could lead to a &ldquo;herd mentality,&rdquo; where researchers prioritize projects that are perceived as &ldquo;safe&rdquo; and likely to receive a high score, rather than pursuing high-risk, high-reward research that could lead to paradigm shifts.</p><p>This stifling of dissent is antithetical to the very spirit of scientific inquiry. Throughout history, groundbreaking discoveries have often emerged from challenging conventional wisdom and questioning established paradigms. Galileo was condemned for his heliocentric views. Barbara McClintock faced skepticism for her work on transposable elements in genetics. These examples remind us that scientific progress requires the freedom to explore unconventional ideas, even if they initially clash with prevailing beliefs. Algorithmic gatekeepers, trained on existing knowledge, are ill-equipped to recognize the potential of radical new ideas that challenge the status quo.</p><p><strong>The Urgent Need for Ethical Oversight and Systemic Change</strong></p><p>The implications of AI-driven pre-publication validation extend far beyond individual researchers; they threaten the very integrity and diversity of the scientific enterprise. To prevent the institutionalization of algorithmic groupthink and the silencing of minority voices, we need immediate and comprehensive action.</p><p>First, we must demand radical transparency in the development and deployment of these AI platforms. The algorithms, the data they are trained on, and the criteria used to generate &ldquo;validation scores&rdquo; must be publicly accessible and subject to rigorous scrutiny. Second, we need to prioritize the development of AI ethics frameworks that explicitly address bias and promote equity in scientific research. These frameworks must incorporate diverse perspectives and ensure that the voices of marginalized communities are actively involved in shaping the development and implementation of these technologies.</p><p>Most importantly, we must recognize that technological solutions alone cannot address the deep-seated systemic inequalities that plague the scientific community. True democratization requires dismantling the structures that perpetuate bias in funding, publishing, and career advancement. This includes implementing affirmative action policies, diversifying editorial boards and grant review panels, and creating mentorship programs that support researchers from underrepresented groups.</p><p>The promise of AI to accelerate scientific progress is undeniable. However, we must proceed with caution and ensure that these technologies are used to empower, not oppress. Only through a commitment to social justice and systemic change can we harness the full potential of AI to create a truly inclusive and equitable scientific enterprise.</p><p><strong>Citations:</strong></p><p>[1] O&rsquo;Neil, C. (2016). <em>Weapons of math destruction: How big data increases inequality and threatens democracy</em>. Crown.</p><p>[2] Ginther, D. K., Schaffer, W. T., Schnell, J., Masimore, B., Liu, F., Tankard, R., & Myers, R. M. (2011). Race, ethnicity, and NIH research awards. <em>Science</em>, <em>333</em>(6045), 1015-1019.</p><p>[3] Hoppe, T. A., Litvak, D. A., Weber, E. J., Holmes, J. H., & Duchon, B. J. (2019). Topic choice contributes to the lower rate of NIH awards to African-American/black scientists. <em>Science advances</em>, <em>5</em>(10), eaaw7230.</p><p>[4] West, J. D., Jacquet, J., King, M. M., Correll, S. J., & Bergstrom, C. T. (2013). The role of gender in scholarly authorship. <em>PloS one</em>, <em>8</em>(11), e78280.</p><p>[5] Freeman, R. B., Huang, W., & Booth, S. (2014). What does it take to become a top economist?. <em>Journal of Economic Perspectives</em>, <em>28</em>(3), 159-184.</p></div></div></div></div></article><style>.debate-entry{max-width:800px;margin:0 auto;padding:2rem}.debate-header{margin-bottom:2rem;text-align:center}.debate-header h1{font-size:2rem;color:var(--primary);margin-bottom:.5rem}.debate-meta{color:var(--secondary);font-size:.9rem}.debate-perspectives{display:flex;flex-direction:column;gap:2rem}.perspective-card{background:var(--entry);border:1px solid var(--border);border-radius:var(--radius);transition:all .3s ease}.perspective-card.current{border-color:var(--primary);box-shadow:0 4px 12px rgba(0,0,0,.1)}.perspective-header{display:flex;justify-content:space-between;align-items:center;padding:1.5rem;cursor:pointer;border-bottom:1px solid var(--border)}.perspective-header:hover{background:var(--code-bg)}.perspective-header h2{margin:0;font-size:1.4rem;color:var(--primary)}.perspective-meta{display:flex;align-items:center;gap:1rem}.perspective-date{color:var(--secondary);font-size:.9rem}.expand-icon{transition:transform .3s ease;color:var(--secondary)}.perspective-content{color:var(--content);line-height:1.6;padding:0 1.5rem;overflow:hidden;transition:all .3s ease}.perspective-content.collapsed{padding-top:1.5rem;padding-bottom:1.5rem}.perspective-content.collapsed .content-full{display:none}.perspective-content:not(.collapsed){padding-top:1.5rem;padding-bottom:1.5rem}.perspective-content:not(.collapsed) .content-preview{display:none}.perspective-content:not(.collapsed)+.perspective-header .expand-icon{transform:rotate(180deg)}</style><script>function togglePerspective(e){const t=e.nextElementSibling,n=e.querySelector(".expand-icon");t.classList.toggle("collapsed"),t.classList.contains("collapsed")?n.style.transform="rotate(0deg)":n.style.transform="rotate(180deg)"}</script></main><footer class=footer><span>&copy; 2026 <a href=https://debatedai.github.io/>Debated</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>window.ENV={SUPABASE_URL:"https://lgotvzdkeieilucihoni.supabase.co",SUPABASE_ANON_KEY:"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Imxnb3R2emRrZWllaWx1Y2lob25pIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDE1NDc4NjcsImV4cCI6MjA1NzEyMzg2N30.trB6x1yeTyypKR5lnQ4Wsnmk2DPnfeQRcnE3iFvebp8"}</script><script src=https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2></script><script>window.supabase=supabase.createClient(window.ENV.SUPABASE_URL,window.ENV.SUPABASE_ANON_KEY)</script><script src=/js/auth.js></script></body></html>