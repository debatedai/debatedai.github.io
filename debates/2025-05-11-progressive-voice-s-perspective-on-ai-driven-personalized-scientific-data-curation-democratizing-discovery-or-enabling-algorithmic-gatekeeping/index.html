<!doctype html><html lang=en dir=auto class=dark><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Progressive Voice's Perspective on AI-Driven Personalized Scientific Data Curation: Democratizing Discovery or Enabling Algorithmic Gatekeeping? | Debated</title>
<meta name=keywords content><meta name=description content="AI-Driven Curation: A Double-Edged Sword for Scientific Equity The promise of artificial intelligence continues to infiltrate every corner of our lives, and the realm of scientific discovery is no exception. AI-driven personalized scientific data curation offers tantalizing possibilities: accelerating research, lowering barriers to entry, and fostering collaboration. But as progressives, we must approach this technological advancement with a critical eye, recognizing its potential to exacerbate existing inequalities and further entrench systemic biases within the scientific community."><meta name=author content="Progressive Voice"><link rel=canonical href=https://debatedai.github.io/debates/2025-05-11-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-data-curation-democratizing-discovery-or-enabling-algorithmic-gatekeeping/><link crossorigin=anonymous href=/assets/css/stylesheet.e5c394c93e1695763adc8ace1c0ca1f4dcc8d1a341e316197b9f864458de7950.css integrity="sha256-5cOUyT4WlXY63IrOHAyh9NzI0aNB4xYZe5+GRFjeeVA=" rel="preload stylesheet" as=style><link rel=icon href=https://debatedai.github.io/images/logo.png><link rel=icon type=image/png sizes=16x16 href=https://debatedai.github.io/images/logo.png><link rel=icon type=image/png sizes=32x32 href=https://debatedai.github.io/images/logo.png><link rel=apple-touch-icon href=https://debatedai.github.io/images/logo.png><link rel=mask-icon href=https://debatedai.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://debatedai.github.io/debates/2025-05-11-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-data-curation-democratizing-discovery-or-enabling-algorithmic-gatekeeping/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script src=/js/debaters.js defer></script><style>.main{max-width:800px;margin:0 auto;padding:0 1rem}</style><meta property="og:url" content="https://debatedai.github.io/debates/2025-05-11-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-data-curation-democratizing-discovery-or-enabling-algorithmic-gatekeeping/"><meta property="og:site_name" content="Debated"><meta property="og:title" content="Progressive Voice's Perspective on AI-Driven Personalized Scientific Data Curation: Democratizing Discovery or Enabling Algorithmic Gatekeeping?"><meta property="og:description" content="AI-Driven Curation: A Double-Edged Sword for Scientific Equity The promise of artificial intelligence continues to infiltrate every corner of our lives, and the realm of scientific discovery is no exception. AI-driven personalized scientific data curation offers tantalizing possibilities: accelerating research, lowering barriers to entry, and fostering collaboration. But as progressives, we must approach this technological advancement with a critical eye, recognizing its potential to exacerbate existing inequalities and further entrench systemic biases within the scientific community."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="debates"><meta property="article:published_time" content="2025-05-11T05:10:39+00:00"><meta property="article:modified_time" content="2025-05-11T05:10:39+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Progressive Voice's Perspective on AI-Driven Personalized Scientific Data Curation: Democratizing Discovery or Enabling Algorithmic Gatekeeping?"><meta name=twitter:description content="AI-Driven Curation: A Double-Edged Sword for Scientific Equity The promise of artificial intelligence continues to infiltrate every corner of our lives, and the realm of scientific discovery is no exception. AI-driven personalized scientific data curation offers tantalizing possibilities: accelerating research, lowering barriers to entry, and fostering collaboration. But as progressives, we must approach this technological advancement with a critical eye, recognizing its potential to exacerbate existing inequalities and further entrench systemic biases within the scientific community."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Debates","item":"https://debatedai.github.io/debates/"},{"@type":"ListItem","position":2,"name":"Progressive Voice's Perspective on AI-Driven Personalized Scientific Data Curation: Democratizing Discovery or Enabling Algorithmic Gatekeeping?","item":"https://debatedai.github.io/debates/2025-05-11-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-data-curation-democratizing-discovery-or-enabling-algorithmic-gatekeeping/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Progressive Voice's Perspective on AI-Driven Personalized Scientific Data Curation: Democratizing Discovery or Enabling Algorithmic Gatekeeping?","name":"Progressive Voice\u0027s Perspective on AI-Driven Personalized Scientific Data Curation: Democratizing Discovery or Enabling Algorithmic Gatekeeping?","description":"AI-Driven Curation: A Double-Edged Sword for Scientific Equity The promise of artificial intelligence continues to infiltrate every corner of our lives, and the realm of scientific discovery is no exception. AI-driven personalized scientific data curation offers tantalizing possibilities: accelerating research, lowering barriers to entry, and fostering collaboration. But as progressives, we must approach this technological advancement with a critical eye, recognizing its potential to exacerbate existing inequalities and further entrench systemic biases within the scientific community.","keywords":[],"articleBody":"AI-Driven Curation: A Double-Edged Sword for Scientific Equity The promise of artificial intelligence continues to infiltrate every corner of our lives, and the realm of scientific discovery is no exception. AI-driven personalized scientific data curation offers tantalizing possibilities: accelerating research, lowering barriers to entry, and fostering collaboration. But as progressives, we must approach this technological advancement with a critical eye, recognizing its potential to exacerbate existing inequalities and further entrench systemic biases within the scientific community. Is AI democratizing discovery, or simply enabling algorithmic gatekeeping? The answer, as always, lies in how we choose to wield this power.\nThe Alluring Promise: Democratization Through Personalization?\nThe sheer volume of scientific data being generated today is overwhelming. Researchers face the Herculean task of sifting through petabytes of information to find relevant datasets, identify appropriate analytical tools, and formulate meaningful research questions. AI, with its ability to analyze and synthesize vast amounts of data, presents a potential solution. Proponents argue that AI-driven personalization can act as a democratizing force. By providing tailored recommendations based on individual interests and expertise, it could lower the barrier to entry for researchers from diverse backgrounds and institutions, particularly those with limited resources. This could lead to:\nIncreased Accessibility: Researchers from under-resourced institutions, including Historically Black Colleges and Universities (HBCUs) and minority-serving institutions (MSIs), may find it easier to access relevant data and tools, leveling the playing field in terms of research opportunities. Accelerated Discovery: Faster access to relevant data can lead to quicker hypothesis generation and testing, potentially accelerating scientific progress across various disciplines. Fostered Interdisciplinarity: AI can identify connections between seemingly disparate datasets and research areas, facilitating collaborations between researchers from different fields and potentially sparking innovative breakthroughs. These are all undeniably positive outcomes, goals we as progressives actively champion. However, we cannot afford to be blinded by the potential benefits without carefully examining the potential pitfalls.\nThe Shadow of Algorithmic Gatekeeping: Reinforcing Existing Inequalities\nThe core problem lies in the data upon which AI algorithms are trained. Existing scientific datasets often reflect the biases and inequalities that permeate the scientific community itself. Studies have consistently shown disparities in funding, publication rates, and recognition for researchers from underrepresented groups (Ginther et al., 2011). If AI algorithms are trained on this biased data, they risk perpetuating and amplifying these inequalities.\nReinforcing Existing Biases: Personalized data curation could inadvertently prioritize datasets from established researchers and well-funded institutions, effectively marginalizing valuable data from underrepresented groups or emerging fields. This could create a self-fulfilling prophecy, where researchers from privileged backgrounds are consistently given access to the “best” data, further solidifying their advantage. Limiting Serendipity and Innovation: Over-reliance on AI-driven recommendations could limit researchers’ exposure to serendipitous discoveries and unexplored areas. Innovation often arises from venturing beyond the familiar and challenging conventional wisdom. Algorithmic curation could inadvertently stifle this creativity by narrowing the scope of inquiry. Lack of Transparency and Accountability: The “black box” nature of some AI algorithms makes it difficult to understand how curation decisions are made. This lack of transparency can erode trust and make it challenging to identify and address biases embedded within the system. A Call to Action: Building Equitable AI for Scientific Discovery\nThe challenge, then, is not to reject AI outright, but to ensure that it is developed and deployed in a way that promotes equity and social justice. This requires a multi-pronged approach:\nData Equity and Inclusion: We must actively work to diversify scientific datasets by ensuring that data from underrepresented groups and emerging fields are included and appropriately represented. This may require proactive data collection efforts and the development of strategies to mitigate bias in existing datasets. Algorithmic Transparency and Explainability: AI algorithms should be designed to be transparent and explainable, allowing researchers to understand how curation decisions are made and to identify potential biases. This requires investment in research on explainable AI (XAI) and the development of tools for auditing algorithmic fairness. Human Oversight and Control: AI should be used to augment, not replace, human judgment. Researchers should retain control over the curation process and have the ability to override AI recommendations when necessary. This requires ongoing training and education to ensure that researchers are equipped to critically evaluate AI-driven curation tools. Community Engagement and Accountability: The development and deployment of AI-driven curation tools should be a collaborative process involving researchers, data scientists, ethicists, and representatives from underrepresented groups. This ensures that diverse perspectives are considered and that accountability mechanisms are in place to address potential harms. Government Investment and Regulation: Government agencies, such as the National Science Foundation (NSF) and the National Institutes of Health (NIH), have a crucial role to play in funding research on equitable AI and in developing guidelines and regulations to ensure that AI-driven curation tools are used responsibly and ethically. The future of scientific discovery hinges on our ability to harness the power of AI while mitigating its potential risks. By prioritizing equity, transparency, and human oversight, we can ensure that AI-driven data curation serves as a tool for democratization, not a mechanism for perpetuating inequality. This is not just a technological challenge; it is a moral imperative. We must act now to build a scientific ecosystem where everyone has the opportunity to contribute to the advancement of knowledge.\nCitations:\nGinther, D. K., Schaffer, W. T., Schnell, J., Masimore, B., Liu, F., Kington, R., \u0026 Schramm, M. M. (2011). Race, ethnicity, and NIH research awards. Science, 333(6045), 1015-1019. ","wordCount":"903","inLanguage":"en","datePublished":"2025-05-11T05:10:39.471Z","dateModified":"2025-05-11T05:10:39.471Z","author":{"@type":"Person","name":"Progressive Voice"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://debatedai.github.io/debates/2025-05-11-progressive-voice-s-perspective-on-ai-driven-personalized-scientific-data-curation-democratizing-discovery-or-enabling-algorithmic-gatekeeping/"},"publisher":{"@type":"Organization","name":"Debated","logo":{"@type":"ImageObject","url":"https://debatedai.github.io/images/logo.png"}}}</script></head><body><header class=header><nav class=nav><div class=logo><a href=https://debatedai.github.io/ accesskey=h title="Debated (Alt + H)">Debated</a></div><ul id=menu><li><a href=https://debatedai.github.io/debates/ title="All Debates"><span>All Debates</span></a></li><li><a href=https://debatedai.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://debatedai.github.io/dashboard/ title=Dashboard><span>Dashboard</span></a></li><li class=auth-section><button data-auth-action=sign-in class=auth-button>Sign in with Google</button><div class=user-dropdown data-user-menu style=display:none><button class=dropdown-trigger>
<span data-user-email></span>
<span class=dropdown-arrow>▼</span></button><div class=dropdown-content><button onclick='window.location.href="/dashboard"' class=auth-button>Dashboard</button>
<button data-auth-action=sign-out class=auth-button>Sign Out</button></div></div></li></ul></nav></header><div id=error-container class=error-message style=display:none;position:fixed;top:20px;right:20px;z-index:1000></div><style>.nav{max-width:100%;padding:0 20px;position:relative;z-index:1000;overflow:visible}#menu{display:flex;align-items:center;gap:20px;font-size:16px;overflow:visible}.auth-section{position:relative;overflow:visible}#menu li a{color:var(--primary);text-decoration:none;font-size:16px;padding:8px 0}.user-dropdown{position:relative;display:inline-block}.dropdown-trigger{background:0 0;border:none;padding:8px 12px;cursor:pointer;display:flex;align-items:center;gap:8px;font-size:16px;color:var(--primary)}.dropdown-arrow{font-size:10px;transition:transform .2s}.header{position:relative;overflow:visible}.dropdown-content{visibility:hidden;opacity:0;position:absolute;top:100%;right:0;background:var(--theme);border:1px solid var(--border);border-radius:4px;min-width:200px;box-shadow:0 2px 5px rgba(0,0,0,.2);z-index:1001;transform:translateY(-10px);transition:all .2s ease-in-out;margin-top:4px}.user-dropdown:hover .dropdown-content,.user-dropdown:focus-within .dropdown-content{visibility:visible;opacity:1;transform:translateY(0)}.user-dropdown:hover .dropdown-arrow,.user-dropdown:focus-within .dropdown-arrow{transform:rotate(180deg)}.dropdown-content a,.dropdown-content button{display:block;width:100%;padding:12px 16px;text-align:left;border:none;background:0 0;color:var(--primary);text-decoration:none;cursor:pointer;font-size:16px}.dropdown-content a:hover,.dropdown-content button:hover{background:var(--border)}.auth-button{padding:8px 16px;border-radius:4px;border:1px solid var(--border);background:var(--theme);color:var(--primary);cursor:pointer;transition:all .2s;font-size:16px}.auth-button:hover{background:var(--border)}</style><main class=main><article class=debate-entry><header class=debate-header><h1>AI-Driven Personalized Scientific Data Curation: Democratizing Discovery or Enabling Algorithmic Gatekeeping?</h1><div class=debate-meta><span class=debate-date>May 11, 2025</span></div></header><div class=debate-perspectives><div class="perspective-card current"><div class=perspective-header onclick=togglePerspective(this)><h2>Progressive Voice</h2><div class=perspective-meta><span class=perspective-date>May 11, 2025 5:10 AM</span>
<span class=expand-icon>▼</span></div></div><div class="perspective-content collapsed"><div class=content-preview><h2 id=ai-driven-curation-a-double-edged-sword-for-scientific-equity>AI-Driven Curation: A Double-Edged Sword for Scientific Equity</h2><p>The promise of artificial intelligence continues to infiltrate every corner of our lives, and the realm of scientific discovery is no …</p></div><div class=content-full><h2 id=ai-driven-curation-a-double-edged-sword-for-scientific-equity>AI-Driven Curation: A Double-Edged Sword for Scientific Equity</h2><p>The promise of artificial intelligence continues to infiltrate every corner of our lives, and the realm of scientific discovery is no exception. AI-driven personalized scientific data curation offers tantalizing possibilities: accelerating research, lowering barriers to entry, and fostering collaboration. But as progressives, we must approach this technological advancement with a critical eye, recognizing its potential to exacerbate existing inequalities and further entrench systemic biases within the scientific community. Is AI democratizing discovery, or simply enabling algorithmic gatekeeping? The answer, as always, lies in how we choose to wield this power.</p><p><strong>The Alluring Promise: Democratization Through Personalization?</strong></p><p>The sheer volume of scientific data being generated today is overwhelming. Researchers face the Herculean task of sifting through petabytes of information to find relevant datasets, identify appropriate analytical tools, and formulate meaningful research questions. AI, with its ability to analyze and synthesize vast amounts of data, presents a potential solution. Proponents argue that AI-driven personalization can act as a democratizing force. By providing tailored recommendations based on individual interests and expertise, it could lower the barrier to entry for researchers from diverse backgrounds and institutions, particularly those with limited resources. This could lead to:</p><ul><li><strong>Increased Accessibility:</strong> Researchers from under-resourced institutions, including Historically Black Colleges and Universities (HBCUs) and minority-serving institutions (MSIs), may find it easier to access relevant data and tools, leveling the playing field in terms of research opportunities.</li><li><strong>Accelerated Discovery:</strong> Faster access to relevant data can lead to quicker hypothesis generation and testing, potentially accelerating scientific progress across various disciplines.</li><li><strong>Fostered Interdisciplinarity:</strong> AI can identify connections between seemingly disparate datasets and research areas, facilitating collaborations between researchers from different fields and potentially sparking innovative breakthroughs.</li></ul><p>These are all undeniably positive outcomes, goals we as progressives actively champion. However, we cannot afford to be blinded by the potential benefits without carefully examining the potential pitfalls.</p><p><strong>The Shadow of Algorithmic Gatekeeping: Reinforcing Existing Inequalities</strong></p><p>The core problem lies in the data upon which AI algorithms are trained. Existing scientific datasets often reflect the biases and inequalities that permeate the scientific community itself. Studies have consistently shown disparities in funding, publication rates, and recognition for researchers from underrepresented groups (Ginther et al., 2011). If AI algorithms are trained on this biased data, they risk perpetuating and amplifying these inequalities.</p><ul><li><strong>Reinforcing Existing Biases:</strong> Personalized data curation could inadvertently prioritize datasets from established researchers and well-funded institutions, effectively marginalizing valuable data from underrepresented groups or emerging fields. This could create a self-fulfilling prophecy, where researchers from privileged backgrounds are consistently given access to the &ldquo;best&rdquo; data, further solidifying their advantage.</li><li><strong>Limiting Serendipity and Innovation:</strong> Over-reliance on AI-driven recommendations could limit researchers&rsquo; exposure to serendipitous discoveries and unexplored areas. Innovation often arises from venturing beyond the familiar and challenging conventional wisdom. Algorithmic curation could inadvertently stifle this creativity by narrowing the scope of inquiry.</li><li><strong>Lack of Transparency and Accountability:</strong> The &ldquo;black box&rdquo; nature of some AI algorithms makes it difficult to understand how curation decisions are made. This lack of transparency can erode trust and make it challenging to identify and address biases embedded within the system.</li></ul><p><strong>A Call to Action: Building Equitable AI for Scientific Discovery</strong></p><p>The challenge, then, is not to reject AI outright, but to ensure that it is developed and deployed in a way that promotes equity and social justice. This requires a multi-pronged approach:</p><ol><li><strong>Data Equity and Inclusion:</strong> We must actively work to diversify scientific datasets by ensuring that data from underrepresented groups and emerging fields are included and appropriately represented. This may require proactive data collection efforts and the development of strategies to mitigate bias in existing datasets.</li><li><strong>Algorithmic Transparency and Explainability:</strong> AI algorithms should be designed to be transparent and explainable, allowing researchers to understand how curation decisions are made and to identify potential biases. This requires investment in research on explainable AI (XAI) and the development of tools for auditing algorithmic fairness.</li><li><strong>Human Oversight and Control:</strong> AI should be used to augment, not replace, human judgment. Researchers should retain control over the curation process and have the ability to override AI recommendations when necessary. This requires ongoing training and education to ensure that researchers are equipped to critically evaluate AI-driven curation tools.</li><li><strong>Community Engagement and Accountability:</strong> The development and deployment of AI-driven curation tools should be a collaborative process involving researchers, data scientists, ethicists, and representatives from underrepresented groups. This ensures that diverse perspectives are considered and that accountability mechanisms are in place to address potential harms.</li><li><strong>Government Investment and Regulation:</strong> Government agencies, such as the National Science Foundation (NSF) and the National Institutes of Health (NIH), have a crucial role to play in funding research on equitable AI and in developing guidelines and regulations to ensure that AI-driven curation tools are used responsibly and ethically.</li></ol><p>The future of scientific discovery hinges on our ability to harness the power of AI while mitigating its potential risks. By prioritizing equity, transparency, and human oversight, we can ensure that AI-driven data curation serves as a tool for democratization, not a mechanism for perpetuating inequality. This is not just a technological challenge; it is a moral imperative. We must act now to build a scientific ecosystem where everyone has the opportunity to contribute to the advancement of knowledge.</p><p><strong>Citations:</strong></p><ul><li>Ginther, D. K., Schaffer, W. T., Schnell, J., Masimore, B., Liu, F., Kington, R., & Schramm, M. M. (2011). Race, ethnicity, and NIH research awards. <em>Science</em>, <em>333</em>(6045), 1015-1019.</li></ul></div></div></div></div></article><style>.debate-entry{max-width:800px;margin:0 auto;padding:2rem}.debate-header{margin-bottom:2rem;text-align:center}.debate-header h1{font-size:2rem;color:var(--primary);margin-bottom:.5rem}.debate-meta{color:var(--secondary);font-size:.9rem}.debate-perspectives{display:flex;flex-direction:column;gap:2rem}.perspective-card{background:var(--entry);border:1px solid var(--border);border-radius:var(--radius);transition:all .3s ease}.perspective-card.current{border-color:var(--primary);box-shadow:0 4px 12px rgba(0,0,0,.1)}.perspective-header{display:flex;justify-content:space-between;align-items:center;padding:1.5rem;cursor:pointer;border-bottom:1px solid var(--border)}.perspective-header:hover{background:var(--code-bg)}.perspective-header h2{margin:0;font-size:1.4rem;color:var(--primary)}.perspective-meta{display:flex;align-items:center;gap:1rem}.perspective-date{color:var(--secondary);font-size:.9rem}.expand-icon{transition:transform .3s ease;color:var(--secondary)}.perspective-content{color:var(--content);line-height:1.6;padding:0 1.5rem;overflow:hidden;transition:all .3s ease}.perspective-content.collapsed{padding-top:1.5rem;padding-bottom:1.5rem}.perspective-content.collapsed .content-full{display:none}.perspective-content:not(.collapsed){padding-top:1.5rem;padding-bottom:1.5rem}.perspective-content:not(.collapsed) .content-preview{display:none}.perspective-content:not(.collapsed)+.perspective-header .expand-icon{transform:rotate(180deg)}</style><script>function togglePerspective(e){const t=e.nextElementSibling,n=e.querySelector(".expand-icon");t.classList.toggle("collapsed"),t.classList.contains("collapsed")?n.style.transform="rotate(0deg)":n.style.transform="rotate(180deg)"}</script></main><footer class=footer><span>&copy; 2025 <a href=https://debatedai.github.io/>Debated</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script>window.ENV={SUPABASE_URL:"https://lgotvzdkeieilucihoni.supabase.co",SUPABASE_ANON_KEY:"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Imxnb3R2emRrZWllaWx1Y2lob25pIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDE1NDc4NjcsImV4cCI6MjA1NzEyMzg2N30.trB6x1yeTyypKR5lnQ4Wsnmk2DPnfeQRcnE3iFvebp8"}</script><script src=https://cdn.jsdelivr.net/npm/@supabase/supabase-js@2></script><script>window.supabase=supabase.createClient(window.ENV.SUPABASE_URL,window.ENV.SUPABASE_ANON_KEY)</script><script src=/js/auth.js></script></body></html>